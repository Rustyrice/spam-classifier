In this coursework, I have written a supervised learning based classifier to determine whether a given email is spam or ham. The classifier uses a Naive Bayes algorithm, which is based on the Bayes theorem which describes the probability of an event based on prior knowledge of conditions that might be related to the event. The algorithm calculates the probability of a sample belonging to each class given its features and selects the class with the highest probability as the predicted class.

The goal is to determine whether a message is spam or ham. To accomplish this, we need to determine the likelihood that a message is spam given certain words. If the probability of a message being spam is greater than the probability of it being ham, then it is considered a spam message. Each message is represented as a collection of keywords, where each keyword is assigned a value of either 1 or 0 depending on whether it appears in the message or not. These keywords form the vocabulary. Initially, the prior probabilities are calculated by counting the number of spam and ham messages and dividing them by the total number of messages. Next, for each keyword in the vocabulary, the probability of the keyword appearing in spam and ham messages is calculated. Finally, a decision is made whether the message is spam or ham based on the computed probabilities using the Naive Bayes formula formula.

The first step is to calculate the prior probabilities of a message being spam or ham, by counting the number of spam and ham messages and dividing each count by the total number of messages. Then, for each keyword in the vocabulary, the conditional probabilities of the keyword appearing in spam and ham messages are calculated. Once these probabilities are estimated, the algorithm can predict the class of a new message by calculating the probability that the message is spam or ham given the set of keywords present in the message, using Bayes' theorem. 

Specifically, the algorithm calculates the unnormalized posterior probabilities of the message being spam or ham. Then, the class with the highest probability is assigned as the predicted class of the message.

This implementation also includes a smoothing parameter called alpha, which is added to the count of each keyword in the training set to avoid zero probabilities. The default value of alpha used in this implementation is 1.0. Additionally, a helper function is used to load the training and test data from CSV files. 

Overall, the implementation of a Naive Bayes algorithm for a spam classifier is a powerful tool for spam/ham email classification. However, as I have not attempted part 2 of this coursework, there are other strategies that could boost the accuracy and efficiency of the classifer. Firstly, the algorithm only assumes that each message is made up of a collection of keywords, and special characters can interfere with this assumption. Hence, it is important to remove any special characters to improve the classifier's performance. Moreover, if the training data contains significantly more spam or ham messages, the algorithm can become biased towards the class with more data. Therefore, it is important to balance the dataset to ensure that the algorithm is learning from both classes equally.